{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Dream Journey"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook allows you to travel through Google's Deep Dream worlds. You can check out Google's app [here](http://deepdreamgenerator.com/) if you don't have an idea of what it is, and [here](https://github.com/google/deepdream) is their notebook with the sources of the project.\n",
    "\n",
    "Google's notebook describes the technology behind their app and how it works. This notebook allows you to travel through the worlds generated by Google!\n",
    "\n",
    "Specifically, you'll be able to generate frames of \"deep\" dreams (when you feed the output of the network back as an input) and create a video from them. You'll also be able to specify where to zoom the picture, so that you select the direction of where to \"go\" in the journey.\n",
    "\n",
    "In general, the notebook provides a nice setup, bringing your image and Google's technology in one context.\n",
    "\n",
    "The github [repository](https://github.com/anatoliykmetyuk/deepdream-journey) contains the latest version of this notebook, make sure to check it out.\n",
    "\n",
    "The project is based on Google's Deep Dream notebook code, it is incapsulated in the [deepdream.py](./deepdream.py) module."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the libraries to be used. The dependencies of this notebook are same as of the Google's deepdream one. You may need to do some heavy setup before running this notebook.\n",
    "\n",
    "The recommended way to install most of the dependencies is to install [Anaconda](https://docs.continuum.io/anaconda/pkg-docs). However, it will not install [PIL](http://www.pythonware.com/products/pil/) and [Caffe](http://caffe.berkeleyvision.org/installation.html) for you - you will need to compile them from sources.\n",
    "\n",
    "Caffe is a work in progress, the hardest part is to get it working. Make sure you follow the instructions on their website and have all the dependencies. If you get a segmentation fault 11 when importing caffe, refer to [this](https://github.com/BVLC/caffe/issues/2677#issuecomment-192470944) solution.\n",
    "\n",
    "Some imports are from the modules from this notebook's root - `deepdream.py` and `deepfront.py`. The former contains Google's code from its deepdream notebook - credit for them. The latter one contains some helpers that are not part of the Google's notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "# imports and basic notebook setup\n",
    "from cStringIO import StringIO\n",
    "import numpy as np\n",
    "import scipy.ndimage as nd\n",
    "import PIL.Image\n",
    "from IPython.display import clear_output, Image, display\n",
    "from google.protobuf import text_format\n",
    "\n",
    "import caffe\n",
    "from deepdream  import deepdream, load_model, showarray\n",
    "from dreamfront import load_img, dream_layers, dream_deep\n",
    "\n",
    "import calendar\n",
    "import time\n",
    "import os\n",
    "\n",
    "# Function to measure time\n",
    "def time_sec():\n",
    "    return calendar.timegm(time.gmtime())\n",
    "\n",
    "# If your GPU supports CUDA and Caffe was built with CUDA support,\n",
    "# uncomment the following to run Caffe operations on the GPU.\n",
    "# caffe.set_mode_gpu()\n",
    "# caffe.set_device(0) # select GPU device if multiple devices exist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to load our neural network. You don't have it out of the box, you'll have to download it from [here](https://github.com/BVLC/caffe/tree/master/models/bvlc_googlenet). Place it under your caffe/models/bvlc_googlenet folder. Then specify the path to your caffe clone under `caffe_path` variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "caffe_path = '/Users/anatolii/Projects/clones/caffe'  # substitute your path here\n",
    "model_path = os.path.join(caffe_path, 'models/bvlc_googlenet/')\n",
    "model, net = load_model(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load an image you will be working with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "base = '.' # Directory where the image is located\n",
    "name = 'sky1024px.jpg' # Name of the image to be opened\n",
    "img = load_img(name, base, scale=0.7) # If the image takes too long to be processed, set `scale` between 0 and 1\n",
    "print(img.shape)\n",
    "showarray(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deepdream function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check whether everything is working and measure how long does `deepdream` function with the standard parameters take."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "t1 = time_sec()\n",
    "dream = deepdream(net, img)\n",
    "time_per_dream = time_sec() - t1\n",
    "\n",
    "print('Dream took %i seconds' % time_per_dream)\n",
    "showarray(dream)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore how all the layers react to deepdream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will run `deepdream` function on all the layers available. You can select a layer with `end` parameter to the `deepdream` function. `dream_layers` function does this for you; you can check it out in the [dreamfront.py](./dreamfront.py) file.\n",
    "\n",
    "Run the following code to see all the layers available."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "net.blobs.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare the directory where you want the output to be generated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_layers_dir='all_layers'\n",
    "!mkdir {all_layers_dir}\n",
    "!rm {all_layers_dir}/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run `deepdream` on all the layers. `iter_n` and `octave_n` will be propagated to the `deepdream` function. `octave_n` is intentionally reduced (originally 4) to speed up things. After running this code, check out your `all_layers_dir` directory for the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dream_layers(net, img, 'all_layers', iter_n=10, octave_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Go deeper!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we feed the outout of `deepdream` back to the network as an input, hence increasing the effect. We save the result of each iteration as an image to the directory.\n",
    "\n",
    "First, prepare this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames_dir='frames'\n",
    "!mkdir {frames_dir}\n",
    "#!rm {frames_dir}/* # Uncomment this if you want the directory to be cleared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate 40 frames, write them to `frames_dir`. You can do more, by changing `frames_n` variable. Also, `iter_n` and `octave_n` are reduced compared to the default ones (originally - 10 and 4 correspondently). Not only this is done for better speed, but also for smoother change between the frames. There are many other parameters to tune, see [deepdream.py](./deepdream.py) from the root of the project for all the parameters you can supply to `deepdream`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dream_deep(net, img, frames_dir, frames_n=40, iter_n=3, octave_n=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate more frames"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just in case your journey into the `deep_dream` was interrupted (or you decided you want more), you can resume from when you ended.\n",
    "\n",
    "First, we search for the last frame generated and output it along with its id."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "frames_paths = [p for p in os.listdir(frames_dir) if os.path.isfile(os.path.join(frames_dir, p))]\n",
    "last_frame_name = frames_paths[-1]\n",
    "last_frame = load_img(last_frame_name, frames_dir)\n",
    "last_frame_id = int(os.path.splitext(last_frame_name)[0]) # ID of the last frame in the frames directory\n",
    "\n",
    "print(last_frame_id)\n",
    "showarray(last_frame)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we continue the generation from the point we ended it.\n",
    "\n",
    "You have probably noticed that the image zooms with each iteration. By default, it zooms on the center. You can change that by passing `dh` and `dw` parameters to `deep_dream`. They specify the coordinate to zoom in, `dh` is a vertical coordinate (`h` for height) and `dw` - the horizontal one (`w` for width). They can take values from 0 to 1, (0, 0) being the upper left corner and (1, 1) - the lower right one. The default parameters are (0.5, 0.5) - for the center.\n",
    "\n",
    "Since zoom resembles joyrney very much, this technique allows you to choose where to travel. Let's go to the right now, also for 40 frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dream_deep(net, last_frame, frames_dir, start_idx=last_frame_id+1, frames_n=40, iter_n=3, octave_n=3, dh=0.5, dw=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make a video"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All these frames from the previous task look very much like they can be the frames of a video. So let's make a video out of them.\n",
    "\n",
    "First, let's check whether you have `ffmpeg` on your system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "!which ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If it produced no output, you don't have it. Install it using your system's package manager. For example, on OS X you can use [homebrew](http://brew.sh/): `brew install ffmpeg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fps=8 # Frames per second\n",
    "filename='movie.mp4' # Where to save the video\n",
    "\n",
    "!ffmpeg -f image2 -r {fps} -i {frames_dir}/%06d.jpg -vcodec mpeg4 -y {filename}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the depth of the world is lost to the end of the journey, so you won't probably be able to travel far like that. Though experimentation never hurts - maybe you'll be the one to find a way! :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
